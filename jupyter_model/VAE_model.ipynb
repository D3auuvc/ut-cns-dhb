{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ac25c1-190d-4fd9-b94e-f72995f8aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import pickle\n",
    "import torch\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8a65e0-d318-4fef-88f3-f34a5a5246ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('./FFT_AllSubject_Training_Face_minmaxNorm','rb')\n",
    "fftdata=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1638b0b3-1b52-407d-a365-8c3a4c029ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((1,3,102,188))\n",
    "for l in range(len(fftdata)):\n",
    "    fftdata[l]=np.where(fftdata[l]>1,1,fftdata[l])\n",
    "    #totalsample+=fftdata[i].shape[0]\n",
    "    result = np.vstack((result,fftdata[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd64f18-dfb2-458f-911b-6e32b9aa5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self,k_size,channel):\n",
    "        super(VAE, self).__init__()\n",
    "        self.device=None\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        # input dim 3*102*188 = 57528\n",
    "        # H = [ (HIn + 2×padding[0]−dilation[0]×(kernel_size[0]−1)−1)/s ] + 1\n",
    "        #   =    [( 102 + 0 - 1x(2) -1 )/2] + 1 \n",
    "        # W = [ (WIn +2×padding[0]−dilation[0]×(kernel_size[0]−1)−1)/s ] + 1\n",
    "        #   = [ ( 188 + 0 - 1x(2) -1 ) /2 ] + 1\n",
    "        # ConvTranspose \n",
    "        # Out =(In−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1\n",
    "        #     = 4x2 - 0 + 2 + 0 + 1 = 11\n",
    "        #     = 9x2 - 0 + 2 + 0 + 1 = 21\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        self.encoder =  torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(channel, 64, k_size, stride=1,padding=1),  #  C=64,H=102,W=188\n",
    "            torch.nn.Conv2d(64, 64, k_size, stride=1,padding=1),  #  C=64,H=102,W=188\n",
    "            self.activation,\n",
    "            self.maxpool,                                         #  C=64,H=50,W=93\n",
    "            torch.nn.Conv2d(64, 128, k_size,stride=1,padding=1),   #  C=128,H=50,W=93\n",
    "            torch.nn.Conv2d(128, 128, k_size,stride=1,padding=1),  #  C=128,H=50,W=93\n",
    "            torch.nn.Conv2d(128, 128, k_size,stride=1,padding=1),  #  C=128,H=50,W=93\n",
    "            self.activation,\n",
    "            self.maxpool,                                          #  C=128,H=24,W=46\n",
    "            torch.nn.Conv2d(128, 256, k_size,stride=1,padding=1),  #  C=256,H=24,W=46\n",
    "            torch.nn.Conv2d(256, 256, k_size,stride=1,padding=1),   #  C=256,H=24,W=46\n",
    "            torch.nn.Conv2d(256, 256, k_size,stride=1,padding=1),   #  C=256,H=24,W=46\n",
    "            self.activation,\n",
    "            self.maxpool,                                          #  C=256,H=11,W=22\n",
    "            torch.nn.Conv2d(256, 512, k_size,stride=1,padding=1),  #  C=512,H=11,W=22\n",
    "            torch.nn.Conv2d(512, 512, k_size,stride=1,padding=1),   #  C=512,H=11,W=22\n",
    "            torch.nn.Conv2d(512, 512, k_size,stride=1,padding=1),   #  C=512,H=11,W=22\n",
    "            self.activation,\n",
    "            self.maxpool                                          #  C=512,H=5,W=10 = 25600 - mu C[0:256] , v C[256:512]\n",
    "        ).to(self.device)\n",
    "        self.decoder =  torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(256, 16, k_size, stride=1,padding=1),  #  C=16,H=5,W=10\n",
    "            torch.nn.Conv2d(16, 32, k_size, stride=1,padding=1),   #  C=32,H=5,W=10\n",
    "            torch.nn.ConvTranspose2d(32,32,(3,4),stride=2),        #  C=32,H=11,W=22\n",
    "            self.activation,\n",
    "            torch.nn.Conv2d(32, 64, k_size,stride=1,padding=1 ),   #  C=64,H=11,W=22\n",
    "            torch.nn.Conv2d(64, 128, k_size,stride=1,padding=1 ),  # C=128,H=11,W=22\n",
    "            torch.nn.ConvTranspose2d(128,128,(4,4),stride=2),      # C=128,H=24,W=46\n",
    "            self.activation,\n",
    "            torch.nn.Conv2d(128, 256, k_size,stride=1,padding=1),   #  C=64,H=24,W=46\n",
    "            torch.nn.Conv2d(256, 32, k_size,stride=1,padding=1),    #  C=32,H=24,W=46\n",
    "            torch.nn.ConvTranspose2d(32,32,(4,3),stride=2),        #  C=32,H=50,W=93\n",
    "            self.activation,\n",
    "            torch.nn.Conv2d(32, 16, k_size,stride=1,padding=1),    #  C=16,H=50,W=93\n",
    "            torch.nn.Conv2d(16, 16, k_size,stride=1,padding=1),    #  C=16,H=50,W=93\n",
    "            torch.nn.ConvTranspose2d(16,3,(4,4),stride=2),          #  C=3,H=102,W=188\n",
    "            torch.nn.Sigmoid()\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.parameters = set()\n",
    "        self.parameters |= set(self.encoder.parameters())\n",
    "        self.parameters |= set(self.decoder.parameters())\n",
    "        self.optimizer = torch.optim.Adam(self.parameters, lr=0.001)\n",
    "        \n",
    "    def reparametrize(self,mu,log_var):\n",
    "        #Reparametrization Trick to allow gradients to backpropagate from the \n",
    "        #stochastic part of the model\n",
    "        sigma = torch.exp(0.5*log_var)\n",
    "        z = torch.randn(mu.size(0),mu.size(1),mu.size(2),mu.size(3),device=self.device)\n",
    "        z= z.type_as(mu)\n",
    "        return mu + sigma*z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        mu = out[:,:256,:,:]\n",
    "        v = out[:,256:,:,:]\n",
    "        #print(mu)\n",
    "        #print(v)\n",
    "        out = self.reparametrize(mu,v)\n",
    "        out = self.decoder(out)\n",
    "        #print(mu)\n",
    "        return out,mu,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e65004ab-3282-4b5b-874c-d8af00a40fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3295\n",
      "epoch:   0 batch: 140 Training Batch Avg loss: 160199027488709.96875000 Validation Batch Avg loss: 0.13245991\n",
      "epoch:   1 batch: 140 Training Batch Avg loss: 0.13140317 Validation Batch Avg loss: 0.12948090\n",
      "epoch:   2 batch: 140 Training Batch Avg loss: 0.12920577 Validation Batch Avg loss: 0.12753223\n",
      "epoch:   3 batch: 140 Training Batch Avg loss: 0.12712301 Validation Batch Avg loss: 0.12532974\n",
      "epoch:   4 batch: 140 Training Batch Avg loss: 0.12496145 Validation Batch Avg loss: 0.12372442\n",
      "epoch:   5 batch: 140 Training Batch Avg loss: 0.12385029 Validation Batch Avg loss: 0.12244790\n",
      "epoch:   6 batch: 140 Training Batch Avg loss: 0.12305862 Validation Batch Avg loss: 0.12178563\n",
      "epoch:   7 batch: 140 Training Batch Avg loss: 0.12239055 Validation Batch Avg loss: 0.12105080\n",
      "epoch:   8 batch: 140 Training Batch Avg loss: 0.12188128 Validation Batch Avg loss: 0.12070738\n",
      "epoch:   9 batch: 140 Training Batch Avg loss: 0.12145520 Validation Batch Avg loss: 0.12040316\n",
      "epoch:  10 batch: 140 Training Batch Avg loss: 0.12121537 Validation Batch Avg loss: 0.12040867\n",
      "epoch:  11 batch: 140 Training Batch Avg loss: 0.12015024 Validation Batch Avg loss: 0.11818452\n",
      "epoch:  12 batch: 140 Training Batch Avg loss: 0.11832596 Validation Batch Avg loss: 0.11693679\n",
      "epoch:  13 batch: 140 Training Batch Avg loss: 0.11750133 Validation Batch Avg loss: 0.11657808\n",
      "epoch:  14 batch: 140 Training Batch Avg loss: 0.11710954 Validation Batch Avg loss: 0.11612384\n",
      "epoch:  15 batch: 140 Training Batch Avg loss: 0.11698935 Validation Batch Avg loss: 0.11611671\n",
      "epoch:  16 batch: 140 Training Batch Avg loss: 0.11685214 Validation Batch Avg loss: 0.11590664\n",
      "epoch:  17 batch: 140 Training Batch Avg loss: 0.11679212 Validation Batch Avg loss: 0.11599713\n",
      "epoch:  18 batch: 140 Training Batch Avg loss: 0.11674764 Validation Batch Avg loss: 0.11584609\n",
      "epoch:  19 batch: 140 Training Batch Avg loss: 0.11669832 Validation Batch Avg loss: 0.11580500\n",
      "epoch:  20 batch: 140 Training Batch Avg loss: 0.11660648 Validation Batch Avg loss: 0.11575340\n",
      "epoch:  21 batch: 140 Training Batch Avg loss: 0.11655118 Validation Batch Avg loss: 0.11573703\n",
      "epoch:  22 batch: 140 Training Batch Avg loss: 0.11650775 Validation Batch Avg loss: 0.11584153\n",
      "epoch:  23 batch: 140 Training Batch Avg loss: 0.11665888 Validation Batch Avg loss: 0.11584968\n",
      "epoch:  24 batch: 140 Training Batch Avg loss: 0.11652029 Validation Batch Avg loss: 0.11571268\n",
      "epoch:  25 batch: 140 Training Batch Avg loss: 0.11646555 Validation Batch Avg loss: 0.11572963\n",
      "epoch:  26 batch: 140 Training Batch Avg loss: 0.11641444 Validation Batch Avg loss: 0.11571507\n",
      "epoch:  27 batch: 140 Training Batch Avg loss: 0.11639538 Validation Batch Avg loss: 0.11566314\n",
      "epoch:  28 batch: 140 Training Batch Avg loss: 0.11634146 Validation Batch Avg loss: 0.11560496\n",
      "epoch:  29 batch: 140 Training Batch Avg loss: 0.11634284 Validation Batch Avg loss: 0.11560352\n",
      "epoch:  30 batch: 140 Training Batch Avg loss: 0.11641153 Validation Batch Avg loss: 0.11564647\n",
      "epoch:  31 batch: 140 Training Batch Avg loss: 0.11641642 Validation Batch Avg loss: 0.11563621\n",
      "epoch:  32 batch: 140 Training Batch Avg loss: 0.11629811 Validation Batch Avg loss: 0.11562964\n",
      "epoch:  33 batch: 140 Training Batch Avg loss: 0.11635620 Validation Batch Avg loss: 0.11564356\n",
      "epoch:  34 batch: 140 Training Batch Avg loss: 0.11628330 Validation Batch Avg loss: 0.11551624\n",
      "epoch:  35 batch: 140 Training Batch Avg loss: 0.11625712 Validation Batch Avg loss: 0.11547224\n",
      "epoch:  36 batch: 140 Training Batch Avg loss: 0.11626094 Validation Batch Avg loss: 0.11545516\n",
      "epoch:  37 batch: 140 Training Batch Avg loss: 0.11625819 Validation Batch Avg loss: 0.11543916\n",
      "epoch:  38 batch: 140 Training Batch Avg loss: 0.11622476 Validation Batch Avg loss: 0.11546614\n",
      "epoch:  39 batch: 140 Training Batch Avg loss: 0.11628539 Validation Batch Avg loss: 0.11566489\n",
      "epoch:  40 batch: 140 Training Batch Avg loss: 0.11628929 Validation Batch Avg loss: 0.11546739\n",
      "epoch:  41 batch: 140 Training Batch Avg loss: 0.11622204 Validation Batch Avg loss: 0.11540701\n",
      "epoch:  42 batch: 140 Training Batch Avg loss: 0.11641573 Validation Batch Avg loss: 0.11583323\n",
      "epoch:  43 batch: 140 Training Batch Avg loss: 0.11633058 Validation Batch Avg loss: 0.11544652\n",
      "epoch:  44 batch: 140 Training Batch Avg loss: 0.11621408 Validation Batch Avg loss: 0.11540090\n",
      "epoch:  45 batch: 140 Training Batch Avg loss: 0.11620800 Validation Batch Avg loss: 0.11539202\n",
      "epoch:  46 batch: 140 Training Batch Avg loss: 0.11617955 Validation Batch Avg loss: 0.11536270\n",
      "epoch:  47 batch: 140 Training Batch Avg loss: 0.11615728 Validation Batch Avg loss: 0.11535900\n",
      "epoch:  48 batch: 140 Training Batch Avg loss: 0.11616164 Validation Batch Avg loss: 0.11536133\n",
      "epoch:  49 batch: 140 Training Batch Avg loss: 0.11615745 Validation Batch Avg loss: 0.11533805\n",
      "epoch:  50 batch: 140 Training Batch Avg loss: 0.11614477 Validation Batch Avg loss: 0.11534612\n",
      "epoch:  51 batch: 140 Training Batch Avg loss: 0.11616193 Validation Batch Avg loss: 0.11533497\n",
      "epoch:  52 batch: 140 Training Batch Avg loss: 0.11620885 Validation Batch Avg loss: 0.11545531\n",
      "epoch:  53 batch: 140 Training Batch Avg loss: 0.11620148 Validation Batch Avg loss: 0.11535305\n",
      "epoch:  54 batch: 140 Training Batch Avg loss: 0.11615059 Validation Batch Avg loss: 0.11533390\n",
      "epoch:  55 batch: 140 Training Batch Avg loss: 0.11612876 Validation Batch Avg loss: 0.11533613\n",
      "epoch:  56 batch: 140 Training Batch Avg loss: 0.11611833 Validation Batch Avg loss: 0.11533667\n",
      "epoch:  57 batch: 140 Training Batch Avg loss: 0.11616875 Validation Batch Avg loss: 0.11538568\n",
      "epoch:  58 batch: 140 Training Batch Avg loss: 0.11613296 Validation Batch Avg loss: 0.11538253\n",
      "epoch:  59 batch: 140 Training Batch Avg loss: 0.11619823 Validation Batch Avg loss: 0.11535794\n",
      "epoch:  60 batch: 140 Training Batch Avg loss: 0.11612876 Validation Batch Avg loss: 0.11534372\n",
      "epoch:  61 batch: 140 Training Batch Avg loss: 0.11609373 Validation Batch Avg loss: 0.11532739\n",
      "epoch:  62 batch: 140 Training Batch Avg loss: 0.11608804 Validation Batch Avg loss: 0.11529934\n",
      "epoch:  63 batch: 140 Training Batch Avg loss: 0.11623154 Validation Batch Avg loss: 0.11538677\n",
      "epoch:  64 batch: 140 Training Batch Avg loss: 0.11612788 Validation Batch Avg loss: 0.11533375\n",
      "epoch:  65 batch: 140 Training Batch Avg loss: 0.11611866 Validation Batch Avg loss: 0.11532460\n",
      "epoch:  66 batch: 140 Training Batch Avg loss: 0.11608151 Validation Batch Avg loss: 0.11529366\n",
      "epoch:  67 batch: 140 Training Batch Avg loss: 0.11605285 Validation Batch Avg loss: 0.11527342\n",
      "epoch:  68 batch: 140 Training Batch Avg loss: 0.11605772 Validation Batch Avg loss: 0.11530028\n",
      "epoch:  69 batch: 140 Training Batch Avg loss: 0.11609120 Validation Batch Avg loss: 0.11538352\n",
      "epoch:  70 batch: 140 Training Batch Avg loss: 0.11608411 Validation Batch Avg loss: 0.11531965\n",
      "epoch:  71 batch: 140 Training Batch Avg loss: 0.11611681 Validation Batch Avg loss: 0.11539938\n",
      "epoch:  72 batch: 140 Training Batch Avg loss: 0.11608825 Validation Batch Avg loss: 0.11530361\n",
      "epoch:  73 batch: 140 Training Batch Avg loss: 0.11609361 Validation Batch Avg loss: 0.11537417\n",
      "epoch:  74 batch: 140 Training Batch Avg loss: 0.11609468 Validation Batch Avg loss: 0.11529474\n",
      "epoch:  75 batch: 140 Training Batch Avg loss: 0.11604280 Validation Batch Avg loss: 0.11528288\n",
      "epoch:  76 batch: 140 Training Batch Avg loss: 0.11606081 Validation Batch Avg loss: 0.11542477\n",
      "epoch:  77 batch: 140 Training Batch Avg loss: 0.11609131 Validation Batch Avg loss: 0.11535464\n",
      "epoch:  78 batch: 140 Training Batch Avg loss: 0.11605370 Validation Batch Avg loss: 0.11528970\n",
      "epoch:  79 batch: 140 Training Batch Avg loss: 0.11604605 Validation Batch Avg loss: 0.11528232\n",
      "epoch:  80 batch: 140 Training Batch Avg loss: 0.11775524 Validation Batch Avg loss: 0.11637232\n",
      "epoch:  81 batch: 140 Training Batch Avg loss: 0.11655900 Validation Batch Avg loss: 0.11553809\n",
      "epoch:  82 batch: 140 Training Batch Avg loss: 0.11625036 Validation Batch Avg loss: 0.11541752\n",
      "epoch:  83 batch: 140 Training Batch Avg loss: 0.11618914 Validation Batch Avg loss: 0.11536939\n",
      "epoch:  84 batch: 140 Training Batch Avg loss: 0.11613969 Validation Batch Avg loss: 0.11535680\n",
      "epoch:  85 batch: 140 Training Batch Avg loss: 0.11610136 Validation Batch Avg loss: 0.11534587\n",
      "epoch:  86 batch: 140 Training Batch Avg loss: 0.11609193 Validation Batch Avg loss: 0.11532983\n",
      "epoch:  87 batch: 140 Training Batch Avg loss: 0.11608126 Validation Batch Avg loss: 0.11534774\n",
      "epoch:  88 batch: 140 Training Batch Avg loss: 0.11607343 Validation Batch Avg loss: 0.11531144\n",
      "epoch:  89 batch: 140 Training Batch Avg loss: 0.11608195 Validation Batch Avg loss: 0.11534258\n",
      "epoch:  90 batch: 140 Training Batch Avg loss: 0.11609245 Validation Batch Avg loss: 0.11534156\n",
      "epoch:  91 batch: 140 Training Batch Avg loss: 0.11617244 Validation Batch Avg loss: 0.11534933\n",
      "epoch:  92 batch: 140 Training Batch Avg loss: 0.11608088 Validation Batch Avg loss: 0.11532531\n",
      "epoch:  93 batch: 140 Training Batch Avg loss: 0.11608471 Validation Batch Avg loss: 0.11531885\n",
      "epoch:  94 batch: 140 Training Batch Avg loss: 0.11618175 Validation Batch Avg loss: 0.11533538\n",
      "epoch:  95 batch: 140 Training Batch Avg loss: 0.11607210 Validation Batch Avg loss: 0.11531740\n",
      "epoch:  96 batch: 140 Training Batch Avg loss: 0.11604252 Validation Batch Avg loss: 0.11529967\n",
      "epoch:  97 batch: 140 Training Batch Avg loss: 0.11604138 Validation Batch Avg loss: 0.11530512\n",
      "epoch:  98 batch: 140 Training Batch Avg loss: 0.11603950 Validation Batch Avg loss: 0.11533729\n",
      "epoch:  99 batch: 140 Training Batch Avg loss: 0.11604477 Validation Batch Avg loss: 0.11529604\n"
     ]
    }
   ],
   "source": [
    "coder = VAE(3,3)\n",
    "#summary(coder,(3,102,188))\n",
    "## Training \n",
    "bceloss=torch.nn.BCELoss()\n",
    "#print(fftdata[1][111,0,0])\n",
    "epoch=100\n",
    "batchsize=10\n",
    "\n",
    "tb = SummaryWriter('Training_CNS/'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_R2_100epoch')\n",
    "length=[x for x in range(result.shape[0])]\n",
    "t=int(np.floor(result.shape[0]*0.7))\n",
    "np.random.shuffle(length)\n",
    "print(t)\n",
    "tidxs=length[:t]\n",
    "vidxs=length[t:]\n",
    "#print(tidxs)\n",
    "batch=t//10\n",
    "vbatch=(result.shape[0]-t)//10\n",
    "bestvloss=float('inf')\n",
    "for e in range(epoch):\n",
    "    trainingloss=0\n",
    "    rloss=0\n",
    "    kloss=0\n",
    "    vloss=0\n",
    "    vrloss=0\n",
    "    vkloss=0\n",
    "    coder.train()\n",
    "    for i in range(batch):\n",
    "        idx=tidxs[i*batchsize:i*batchsize+batchsize]\n",
    "        #print(idx)\n",
    "        data = torch.tensor(result[idx,:,:,:]).float().to(coder.device)\n",
    "        out,mu,v = coder(data)\n",
    "        regconstructionloss = bceloss(out,data)\n",
    "        KLDloss = - 0.5 * torch.sum(1+ v - mu.pow(2) - v.exp())\n",
    "            #print(f'R {regconstructionloss}')\n",
    "            #print(f'K {KLDloss}')\n",
    "        totalloss=regconstructionloss+KLDloss\n",
    "        coder.optimizer.zero_grad()\n",
    "        trainingloss+=totalloss.item()\n",
    "        rloss+=regconstructionloss.item()\n",
    "        kloss+=KLDloss.item()\n",
    "        totalloss.backward()\n",
    "        coder.optimizer.step()\n",
    "        \n",
    "    coder.eval()\n",
    "    for i in range(vbatch):\n",
    "        idx=vidxs[i*batchsize:i*batchsize+batchsize]\n",
    "        #print(idx)\n",
    "        data = torch.tensor(result[idx,:,:,:]).float().to(coder.device)\n",
    "        out,mu,v = coder(data)\n",
    "        regconstructionloss = bceloss(out,data)\n",
    "        KLDloss = - 0.5 * torch.sum(1+ v - mu.pow(2) - v.exp())\n",
    "            #print(f'R {regconstructionloss}')\n",
    "            #print(f'K {KLDloss}')\n",
    "        loss=regconstructionloss+KLDloss\n",
    "        vloss+=loss.item()\n",
    "        vrloss+=regconstructionloss.item()\n",
    "        vkloss+=KLDloss.item()\n",
    "        #print(totalloss.item())\n",
    "    if(vloss<bestvloss):\n",
    "        torch.save(coder,'./Model_CNS/bmodel_'+str(vloss/vbatch))\n",
    "        bestvloss=vloss\n",
    "        \n",
    "    tb.add_scalar(\"Training Avg Loss\", (trainingloss/batch), e)\n",
    "    tb.add_scalar(\"Training Avg RLoss\", (rloss/batch), e)\n",
    "    tb.add_scalar(\"Training Avg KLoss\", (kloss/batch), e)\n",
    "    tb.add_scalar(\"Validation Avg Loss\", (vloss/vbatch), e)\n",
    "    tb.add_scalar(\"Validation Avg RLoss\", (vrloss/vbatch), e)\n",
    "    tb.add_scalar(\"Validation Avg KLoss\", (vkloss/vbatch), e)\n",
    "   \n",
    "    for name, weight in coder.encoder.named_parameters():\n",
    "        tb.add_histogram('encoder'+name,weight, e)\n",
    "        tb.add_histogram(f'encoder_{name}.grad',weight.grad, e)\n",
    "    for name, weight in coder.decoder.named_parameters():\n",
    "        tb.add_histogram('decoder'+name,weight, e)\n",
    "        tb.add_histogram(f'decoder_{name}.grad',weight.grad, e)\n",
    "    print(f'epoch: {e:3} batch: {i:3} Training Batch Avg loss: {trainingloss/batch:10.8f} Validation Batch Avg loss: {vloss/vbatch:10.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b77d907c-a1a2-4f58-a9ed-bb97b56deaaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15253/2379263994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfftdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfftdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "fftdata1 = np.asarray(fftdata, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66975fb1-f281-4049-9619-98d6f02d7d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(fftdata[1]<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59db49-806f-4a9b-b5ce-246c16fec3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
